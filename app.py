import cv2
import streamlit as st
from ultralytics import YOLO
import tempfile
import os
import gc

st.set_page_config(layout="wide")

col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.image("–≥—Ä–∞—Ñ–∏–∫–∏ –∏ –ª–æ–≥–æ/–ª–æ–≥–æ2.jpg", width=800)
st.markdown("---")

@st.cache_resource
def load_model():
    return YOLO('best.pt', task='detect')

model = load_model()

video_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ (–¥–æ 1GB)", type=["mp4", "avi", "mov"])

if video_file:
    if video_file.size > 1000 * 1024 * 1024:
        st.error("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: 1GB")
        st.stop()

    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
        tfile.write(video_file.read())
        video_path = tfile.name

    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –≤–∏–¥–µ–æ")
            st.stop()

        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        st.sidebar.info(f"""
        –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤–∏–¥–µ–æ:
        - –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {width}x{height}
        - –ß–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤: {fps:.1f}
        - –í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤: {total_frames}
        """)

        skip_frames = st.sidebar.slider(
            "–ü—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤",
            0, 10, 2,
            help="–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É"
        )

        progress_bar = st.progress(0)
        status_text = st.empty()
        video_box = st.empty()
        frame_count = 0

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1
            if frame_count % (skip_frames + 1) != 0:
                continue

            try:
                # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –ø–æ–ª–Ω–æ–º –∫–∞–¥—Ä–µ
                results = model(frame, imgsz=640, conf=0.5, verbose=False)

                if len(results[0].boxes) > 0:
                    status_text.success(f"üöó –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω (–∫–∞–¥—Ä {frame_count})")
                else:
                    status_text.warning(f"üö´ –ù–µ—Ç —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ (–∫–∞–¥—Ä {frame_count})")

                annotated_frame = results[0].plot()
                video_box.image(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))

                del results
                gc.collect()

            except Exception as e:
                status_text.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")
                continue

            progress_bar.progress(min(frame_count / total_frames, 1.0))

        cap.release()
        st.balloons()
        st.success("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
    finally:
        if os.path.exists(video_path):
            os.unlink(video_path)

else:
    st.info("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞")
